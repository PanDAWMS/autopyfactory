#
# queues.conf  Configuration file for APFQueue component of AutoPyFactory.
#

## Defaults for queues - these values are set when there is not an explicit value
## If you don't set them here the factory takes sensible default values, so nothing is mandatory
## see ConfigLoader._configurationDefaults() for these values. 
#
# Most important values can now be detected from schedconfig, so there is no need to set them
# at all. These values are marked with a *. N.B. Even if you do set these values in the factory
# they will be overwritten unless the "override = True" setting is used.
#
# Some of these values may be in the process of deprecation, especially submission parameters 
# which are now handled by the submit plugins. 

# =========================================================================== 
#               VARIABLES
# =========================================================================== 

# override
#
# cloud
# nickname
# siteid
# proxy
# enabled
# status
# apfqueue.sleep
#
# cleanlogs.maxdays
#
# wmsstatusplugin
#
# batchstatusplugin
#
# schedplugin
# sched.activated.default
# sched.activated.max_jobs_torun
# sched.activated.max_pilots_per_cycle
# sched.activated.min_pilots_per_cycle
# sched.activated.max_pilots_pending
# sched.fixed.pilotspercycle
# sched.simple.default
# sched.simple.maxpendingpilots
# sched.simple.maxpilotspercycle
# sched.simplenqueue.default
# sched.simplenqueue.maxpilotspercycle
# sched.simplenqueue.nqueue
# sched.simplenqueue.depthboost
# sched.simplenqueue.pilotlimit
# sched.simplenqueue.transferringlimit
# sched.trivial.default
#
# batchsubmitplugin
# batchsubmit.condorgt2.gridresource
# batchsubmit.condorgt2.condor_attributes
# batchsubmit.condorgt2.environ
# batchsubmit.condorgt2.queue
# batchsubmit.condorgt5.gridresource
# batchsubmit.condorgt5.condor_attributes
# batchsubmit.condorgt5.environ
# batchsubmit.condorgt5.queue
# batchsubmit.condorcream.gridresource
# batchsubmit.condorcream.condor_attributes
# batchsubmit.condorcream.environ
# batchsubmit.condorcream.queue
# batchsubmit.condorcream.port
# batchsubmit.condorcream.batch
# batchsubmit.condorec2.gridresource
# batchsubmit.condorec2.condor_attributes
# batchsubmit.condorec2.environ
# batchsubmit.condorec2.ami_id
# batchsubmit.condorec2.instance_type
# batchsubmit.condorec2.user_data
# batchsubmit.condorec2.access_key_id
# batchsubmit.condorec2.secret_access_key
# batchsubmit.condorlocal.condor_attributes
# batchsubmit.condorlocal.environ
#
# executable
# executable.arguments
# executable.wrappervo
# executable.wrappergrid
# executable.wrapperpurpose
# executable.wrapperserverurl
# executable.wrappertarballurl
# executable.wrapperspecialcmd
# executable.wrapperplugin
# executable.wrapperpilottype
# executable.wrapperloglevel
# executable.wrappermode

# =========================================================================== 
#               DESCRIPTION 
# =========================================================================== 

#  --------------------------------------------------------------------
#       Generic variables
#  --------------------------------------------------------------------

# override = determines if values from this config file have precedence over
#               the same values comming from different sources of information.
#               If True then schedconfig does not clobber configuration file values.
#               Valid values are True|False.
#
# cloud = is the cloud this queue is in. You should set this to suppress pilot 
#               submission when the cloud goes offline
#               N.B. Panda clouds are UPPER CASE, e.g., UK
#
# nickname = PanDA queue name   
#
# siteid = PanDA siteid name
#
# proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#
# enabled = determines if each queue section must be used by AutoPyFactory
#               or not. Allows to disable a queue without commenting out all the values. 
#               Valid values are True|False.
#
# status = can be "test", "offline" or "online"
#
# apfqueue.sleep = sleep time between cycles in APFQueue object.
#               Value is in seconds.   
#
# cleanlogs.maxdays = maximum number of days the condor logs
#               will be kept

#  --------------------------------------------------------------------
#       WMS Status Plugin variables 
#  --------------------------------------------------------------------

# wmsstatusplugin = WMS Status Plugin.

#  --------------------------------------------------------------------
#       Batch Status Plugin variables 
#  --------------------------------------------------------------------

# batchstatusplugin = Batch Status Plugin.

#  --------------------------------------------------------------------
#       Sched Plugin variables 
#  --------------------------------------------------------------------

# schedplugin = specific Scheduler Plugin implementing
#               the algorithm deciding how many new pilots
#               to submit next cycle.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Activated
#  --------------------------------------------------------------------

# sched.activated.default = default number of pilots to be submitted
#               when the context information 
#               does not exist is not reliable 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_jobs_torun = maximum number of jobs running
#               simoultaneously. 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_per_cycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_per_cycle = minimum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_pending = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Fixed
#  --------------------------------------------------------------------

# sched.fixed.pilotspercycle = fixed number of pilots to be submitted
#               each cycle, when using the Fixed Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Simple
#  --------------------------------------------------------------------

# sched.simple.default = default number of pilots to be submitted
#               when the context information does not exist
#               or is not reliable.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpendingpilots = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpilotspercycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Simple Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is SimpleNQueue
#  --------------------------------------------------------------------

# sched.simplenqueue.default = default number of pilots to be submitted
#               when the context information does not exist 
#               or is not reliable.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.maxpilotspercycle = maximum number of pilots
#               to be submitted each cycle.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.nqueue = desired number of pilots
#               in idle status waiting in queue to start execution.
#               To be used in SimpleNQueue Scheduler Plugin.
# sched.simplenqueue.depthboost = multiplying factor which allows more pilots 
#               to be submitted than nqueue if there are 
#               sufficient activated jobs - helps when the jobs are short 
#
# sched.simplenqueue.pilotlimit = sets a hard limit on the total number 
#               of pilots at a site, active + queued
#
# sched.simplenqueue.transferringlimit = sets a limit on the number of jobs 
#               in transferring status allowed at a site - 
#               when this limit is reached no pilots will be submitted 
#               to allow backlogs to clear

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Trivial
#  --------------------------------------------------------------------

# sched.trivial.default = default number of pilots
#               to be submitted when the context information
#               does not exist or is not reliable.
#               To be used in Trivial Scheduler Plugin.

#  --------------------------------------------------------------------
#       Batch Submit Plugin variables 
#  --------------------------------------------------------------------

# batchsubmitplugin = Batch Submit Plugin.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt2
#  --------------------------------------------------------------------

# batchsubmit.condorgt2.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt2.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#                       periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#                       +Nonessential = True
#
# batchsubmit.condorgt2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#
# batchsubmit.condorgt2.queue = queue within the local batch system (e.g. short)

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt5
#  --------------------------------------------------------------------

# batchsubmit.condorgt5.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt5.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#                       periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#                       +Nonessential = True
#
# batchsubmit.condorgt5.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#
# batchsubmit.condorgt5.queue = queue within the local batch system (e.g. short)

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorcream
#  --------------------------------------------------------------------

# batchsubmit.condorcream.gridresource = web service address (e.g. ce04.esc.qmul.ac.uk:8443/ce-cream/services/CREAM2)
#
# batchsubmit.condorcream.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#                       periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#                       +Nonessential = True
#
# batchsubmit.condorcream.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#
# batchsubmit.condorcream.queue = queue within the local batch system (e.g. short)
#
# batchsubmit.condorcream.port = port number.
#
# batchsubmit.condorcream.batch = local batch system (pbs, sge...)

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorec2
#  --------------------------------------------------------------------

# batchsubmit.condorec2.gridresource = ec2 service's URL (e.g. https://ec2.amazonaws.com/ )
#
# batchsubmit.condorec2.condor_attributes list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#
# batchsubmit.condorec2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#
# batchsubmit.condorec2.ami_id = identifier for the VM image, 
#               previously registered in one of Amazon's storage service (S3 or EBS)
#
# batchsubmit.condorec2.instance_type = hardware configurations for instances to run on.
#
# batchsubmit.condorec2.user_data = up to 16Kbytes of contextualization data.
#               This makes it easy for many instances to share the same VM image, but perform different work.
#
# batchsubmit.condorec2.access_key_id = path to file with the EC2 Access Key ID
#
# batchsubmit.condorec2.secret_access_key = path to file with the EC2 Secret Access Key

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorlocal
#  --------------------------------------------------------------------

# batchsubmit.condorlocal.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       universe = vanilla
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#
#               To be used in CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorlocal.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorLocal Batch Submit Plugin.
#

#  --------------------------------------------------------------------
#       Executable variables 
#  --------------------------------------------------------------------

# executable = the script which will be run by condor. 
#
# executable.arguments = input options to be passed verbatim to the executable script.
#
# executable.wrappervo = VO
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperpurpose = specific purpose for the job, if needed (e.g. testing, prod, analysis)
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.specialcmd = is special command to be performed, 
#               for some specific reason, just after sourcing the Grid environment,
#               but before doing anything else.
#               This has been triggered by the need to execute command
#                    $ module load <module_name>
#               at NERSC after sourcing the OSG grid environment. 
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperplugin = is the plug-in module with the code corresponding 
#               to the final wrapper flavor, in case its value is different that
#               the one provided by the wrapper config files.
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappperpilottype = is the actual  pilot code to be executed at the end,
#               in case its value is different that the one provided 
#               by the wrapper config files.        
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappermode = specifies a particular mode of operation
#               (e.g. test)
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappergrid = type of Grid Midleware (e.g. OSG).
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperloglevel = log level.
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperserverurl =  base URL with the VO-specific pilot tarball
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappertarballurl =  URL with the wrapper tar ball
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# =========================================================================== 


[DEFAULT]

cloud = US
country = US
group = None
status = online

# plugins
batchstatusplugin = Condor
wmsstatusplugin = Panda
batchsubmitplugin = CondorGT2
schedplugin = Activated

sched.trivial.default = 0
sched.simple.default = 0
sched.simplenqueue.default = 0
sched.activated.default = 0

# proxy = atlas-usatlas
proxy = None

apfqueue.sleep = 360

executable = /usr/libexec/wrapper.sh
executable = wrappervo = ATLAS
executable.wrappertarballurl = http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz
executable.wrapperserverurl = http://pandaserver.cern.ch:25080/cache/pilot
executable.wrapperloglevel = debug


override = True
enabled = True

# ====================================================================== 
#               Individual queue configurations
# ====================================================================== 

[BNL_ITB_Test1]
enabled = False
siteid = BNL_ITB_Test1
nickname = BNL_ITB_Test1-condor
batchsubmit.condorgt2.gridresource = gridtest01.racf.bnl.gov/jobmanager-condor

executable.wrappergrid = OSG
executable.arguments = -j false -k 600 -u panda 

schedplugin = Activated

batchsubmitplugin = CondorLocal
batchsubmit.condorlocal.localqueue = OSG_ITB_Jose
batchsubmit.condorlocal.condor_attributes = +RACF_Group = "osgitb",+Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
batchsubmit.condorlocal.environ = OSG_GRID=/afs/usatlas/osg/wn-client/@sys/itb



# ------------------------------------------------------------------------

[ANALY_BNL_ATLAS_1]
enabled = False
siteid = ANALY_BNL_ATLAS_1
nickname = ANALY_BNL_ATLAS_1-condor
batchsubmit.condorgt2.gridresource = gridgk05.racf.bnl.gov/jobmanager-condor

executable.wrappergrid = OSG
executable.wrapperloglevel = debug
executable.arguments = --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache -f false -m false --user user

proxy = atlas-production

schedplugin = Activated
sched.activated.min_pilots_per_cycle = 0
sched.activated.max_pilots_per_cycle = 10
sched.activated.max_jobs_torun = 60

batchsubmit.condorgt2.queue = short
batchsubmit.condorgt2.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)

