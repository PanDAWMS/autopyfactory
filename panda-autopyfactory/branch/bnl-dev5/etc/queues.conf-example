#
# queues.conf  Configuration file for APFQueue component of AutoPyFactory.
#

## Defaults for queues - these values are set when there is not an explicit value
## If you don't set them here the factory takes sensible default values, so nothing is mandatory
## see ConfigLoader._configurationDefaults() for these values. 
#
# Most important values can now be detected from schedconfig, so there is no need to set them
# at all. These values are marked with a *. N.B. Even if you do set these values in the factory
# they will be overwritten unless the "override = True" setting is used.
#
# Some of these values may be in the process of deprecation, especially submission parameters 
# which are now handled by the submit plugins. 

# =========================================================================== 
#               VARIABLES
# =========================================================================== 

# override
#
# cloud
# nickname
# siteid
# proxy
# enabled
# status
#
# cleanlogs.maxdays
#
# schedplugin
# sched.activated.default
# sched.activated.max_jobs_torun
# sched.activated.max_pilots_per_cycle
# sched.activated.min_pilots_per_cycle
# sched.activated.max_pilots_pending
# sched.fixed.pilotspercycle
# sched.simple.default
# sched.simple.maxpendingpilots
# sched.simple.maxpilotspercycle
# sched.simplenqueue.default
# sched.simplenqueue.maxpilotspercycle
# sched.simplenqueue.nqueue
# sched.simplenqueue.depthboost
# sched.simplenqueue.pilotlimit
# sched.simplenqueue.transferringlimit
# sched.trivial.default
#
# wmsstatusplugin
# apfqueue.sleep
#
# batchstatusplugin
#
# batchsubmitplugin
# batchsubmit.condorgrid.condor_attributes
# batchsubmit.condorgrid.environ
# batchsubmit.condorgrid.queue
# batchsubmit.condorgrid.gridresource
# batchsubmit.condorgrid.gktype
# batchsubmit.condorgram.gramversion
# batchsubmit.condorlocal.condor_attributes
# batchsubmit.condorlocal.environ
# batchsubmit.condorec2.condor_attributes
# batchsubmit.condorec2.environ
# batchsubmit.condorec2.ami_id
# batchsubmit.condorec2.instance_type
# batchsubmit.condorec2.user_data
# batchsubmit.condorec2.access_key_id
# batchsubmit.condorec2.secret_access_key
#
# executable
# executable.arguments
# executable.wrappervo
# executable.wrappergrid
# executable.wrapperpurpose
# executable.wrapperserverurl
# executable.wrappertarballurl
# executable.wrapperspecialcmd
# executable.wrapperplugin
# executable.wrapperpilottype
# executable.wrapperloglevel
# executable.wrappermode

# ---------------------------------------------------------------------------
# Description:
# ---------------------------------------------------------------------------

# override = determines if values from this config file have precedence over
#               the same values comming from different sources of information.
#               If True then schedconfig does not clobber configuration file values.
#               Valid values are True|False.
#
# cloud = is the cloud this queue is in. You should set this to suppress pilot 
#               submission when the cloud goes offline
#               N.B. Panda clouds are UPPER CASE, e.g., UK
#
# nickname = PanDA queue name   
#
# siteid = PanDA siteid name
#
# proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#
# enabled = determines if each queue section must be used by AutoPyFactory
#               or not. Allows to disable a queue without commenting out all the values. 
#               Valid values are True|False.
#
# status = can be "test", "offline" or "online"
#
# cleanlogs.maxdays = maximum number of days the condor logs
#               will be kept
#
# schedplugin = specific Scheduler Plugin implementing
#               the algorithm deciding how many new pilots
#               to submit next cycle.
#
# sched.activated.default = default number of pilots to be submitted
#               when the context information 
#               does not exist is not reliable 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_jobs_torun = maximum number of jobs running
#               simoultaneously. 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_per_cycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_per_cycle = minimum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_pending = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.
#
# sched.fixed.pilotspercycle = fixed number of pilots to be submitted
#               each cycle, when using the Fixed Scheduler Plugin.
#
# sched.simple.default = default number of pilots to be submitted
#               when the context information does not exist
#               or is not reliable.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpendingpilots = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpilotspercycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Simple Scheduler Plugin.
#
# sched.simplenqueue.default = default number of pilots to be submitted
#               when the context information does not exist 
#               or is not reliable.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.maxpilotspercycle = maximum number of pilots
#               to be submitted each cycle.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.nqueue = desired number of pilots
#               in idle status waiting in queue to start execution.
#               To be used in SimpleNQueue Scheduler Plugin.
# sched.simplenqueue.depthboost = multiplying factor which allows more pilots 
#               to be submitted than nqueue if there are 
#               sufficient activated jobs - helps when the jobs are short 
#
# sched.simplenqueue.pilotlimit = sets a hard limit on the total number 
#               of pilots at a site, active + queued
#
# sched.simplenqueue.transferringlimit = sets a limit on the number of jobs 
#               in transferring status allowed at a site - 
#               when this limit is reached no pilots will be submitted 
#               to allow backlogs to clear
#
# sched.trivial.default = default number of pilots
#               to be submitted when the context information
#               does not exist or is not reliable.
#               To be used in Trivial Scheduler Plugin.
#
# wmsstatusplugin = WMS Status Plugin.
#
# apfqueue.sleep = sleep time between cycles in APFQueue object.
#               Value is in seconds.   
#
# batchstatusplugin = Batch Status Plugin.
#
# batchsubmitplugin = Batch Submit Plugin.
#
# batchsubmit.condorgrid.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#                       periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#                       +Nonessential = True
#
#               To be used in CondorGRAM Batch Submit Plugin.
#
# batchsubmit.condorgrid.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorGRAM Batch Submit Plugin.
#
# batchsubmit.condorgrid.queue = local batch queue 
#               to be included in the globusrsl directive.
#               To be used by CondorGRAM Batch Submit Plugin.
#
# batchsubmit.condorgrid.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#               Used only for remote submission when the gktype is gram
#
# batchsubmit.condorgrid.gktype = type of gatekeeper. 
#               Valid options are 
#               -- "gram": for gk2, gk4, gk5 (default)
#               -- "cream"
#
# batchsubmit.condorgram.gramversion = version of the GRAM protocol, eg, 2, 5, ...
#               Used only for remote submission when the gktype is gram
#
# batchsubmit.condorlocal.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       universe = vanilla
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#
#               To be used in CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorlocal.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorec2.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#
# batchsubmit.condorec2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorec2.ami_id = identifier of the image, already stored 
#               (either in S3 or EBS) and registered.
#
# batchsubmit.condorec2.instance_type = hardware configuration (default is m1.small)
#
# batchsubmit.condorec2.user_data =  up to 16 Kbytes of text to contextualize the VM 
#
# batchsubmit.condorec2.access_key_id = path to file with the EC2 Access Key ID
#
# batchsubmit.condorec2.secret_access_key = path to file with the EC2 Secret Access Key
#
# executable = the script which will be run by condor. 
#
# executable.arguments = input options to be passed verbatim to the executable script.
#
# executable.wrappervo = VO
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperpurpose = specific purpose for the job, if needed (e.g. testing, prod, analysis)
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.specialcmd = is special command to be performed, 
#               for some specific reason, just after sourcing the Grid environment,
#               but before doing anything else.
#               This has been triggered by the need to execute command
#                    $ module load <module_name>
#               at NERSC after sourcing the OSG grid environment. 
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperplugin = is the plug-in module with the code corresponding 
#               to the final wrapper flavor, in case its value is different that
#               the one provided by the wrapper config files.
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappperpilottype = is the actual  pilot code to be executed at the end,
#               in case its value is different that the one provided 
#               by the wrapper config files.        
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappermode = specifies a particular mode of operation
#               (e.g. test)
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappergrid = type of Grid Midleware (e.g. OSG).
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperloglevel = log level.
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrapperserverurl =  base URL with the VO-specific pilot tarball
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# executable.wrappertarballurl =  URL with the wrapper tar ball
#               To be used by the 'new wrapper' distributed with AutoPyFactory.
#
# =========================================================================== 


[DEFAULT]

cloud = US
country = US
group = None
status = online

# plugins
batchstatusplugin = Condor
wmsstatusplugin = Panda
batchsubmitplugin = CondorGRAM
schedplugin = Activated

sched.trivial.default = 0
sched.simple.default = 0
sched.simplenqueue.default = 0
sched.activated.default = 0

# proxy = atlas-usatlas
proxy = None

apfqueue.sleep = 360

executable = /usr/libexec/wrapper.sh
executable = wrappervo = ATLAS
executable.wrappertarballurl = http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz
executable.wrapperserverurl = http://pandaserver.cern.ch:25080/cache/pilot
executable.wrapperloglevel = debug

batchsubmit.condorgrid.gktype = gram
batchsubmit.condorgram.gramversion = 2

override = True
enabled = True

# ====================================================================== 
#               Individual queue configurations
# ====================================================================== 

[BNL_ITB_Test1]
enabled = False
siteid = BNL_ITB_Test1
nickname = BNL_ITB_Test1-condor
batchsubmit.condorgrid.gridresource = gridtest01.racf.bnl.gov/jobmanager-condor

executable.wrappergrid = OSG
executable.arguments = -j false -k 600 -u panda 

schedplugin = Activated

batchsubmitplugin = CondorLocal
batchsubmit.condorlocal.localqueue = OSG_ITB_Jose
batchsubmit.condorlocal.condor_attributes = +RACF_Group = "osgitb",+Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
batchsubmit.condorlocal.environ = OSG_GRID=/afs/usatlas/osg/wn-client/@sys/itb



# ------------------------------------------------------------------------

[ANALY_BNL_ATLAS_1]
enabled = False
siteid = ANALY_BNL_ATLAS_1
nickname = ANALY_BNL_ATLAS_1-condor
batchsubmit.condorgrid.gridresource = gridgk05.racf.bnl.gov/jobmanager-condor

executable.wrappergrid = OSG
executable.wrapperloglevel = debug
executable.arguments = --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache -f false -m false --user user

proxy = atlas-production

schedplugin = Activated
sched.activated.min_pilots_per_cycle = 0
sched.activated.max_pilots_per_cycle = 10
sched.activated.max_jobs_torun = 60

batchsubmit.condorgrid.queue = short

