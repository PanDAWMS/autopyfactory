autopyfactory
-------------

autopyfactory is a (still fairly) simple pilot factory for ATLAS
production. Configured sites have pilots dispatched to them depending
on their status in production (i.e., if jobs are waiting to be picked
up) and how many pilots are currently queued or running.

autopyfactory will now mainly autoconfigure itself from schedconfig
so only queue nicknames need be defined.


How the factory works:

For each site the factory looks at the status of jobs already
submitted (running and queued) and the status of the site in panda
production (particularly activated jobs, which are the jobs now ready
to run at the site).

For sites which are "online" in panda and have activated jobs
the factory ensures that a minimum depth of queued jobs are maintained
on the site. If the site has no activated jobs the factory idles the
site by sending one pilot.


How the pilot wrapper works:

The default wrapper is called runpilot3-wrapper.sh. Essentially
it changes to a proper working directory, fetches the pilot tarball
(downloaded via curl), prints out some useful debug environment 
information, finds a working python for the LFC plugin, then fires 
off the pilot code. Recently added features include sourcing the DDM 
setup code and the ATLAS local site setup scripts.


Building
--------

To build this package from source do

python setup.py bdist --formats=rpm

*** N.B. Because of a problem in the way Redhat flavour RPMs are built
you must have this rpm macro defined:

%_unpackaged_files_terminate_build 0

which prevents rpmbuild from failing because of the .pyo files which
get built automatically.

The easiest way to do this is to add that line to ~/.rpmmacros.

Monitoring
----------

With monitoring enabled autopyfactory will send HTTP_GET and HTTP_POST
requests to a remote webservice. The following requests are made:

1. HTTP_POST for each condor job CREATED  (Factory.py)
2. HTTP_GET when pilot job is RUNNING on WorkerNode (runpilot3-wrapper.sh)
3. HTTP_GET when pilot job is EXITING on WorkerNode (runpilot3-wrapper.sh)

In addition, two cron jobs are required to update the monitoring webservice
about he state of each job:

1. mon-exiting.sh refreshes jobs in state EXITING
2. mon-stale.sh notifies webservice about jobs which are stuck in particular
states based on pre-defined timeouts.

The monitoring webservice display views based on this information to give an 
overview on pilot factory health.
