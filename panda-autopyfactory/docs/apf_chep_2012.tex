\documentclass[a4paper]{jpconf}
%\usepackage{graphicx}
\begin{document}
\title{AutoPyFactory: A Scalable Flexible Pilot Factory Implementation}

\author{J. Caballero$^1$, J. Hover $^1$, P. Love$^2$, G. Stewart$^3$}

\address{$^1$ Brookhaven National Laboratory, PO BOX 5000 Upton, NY 11973, USA}
\address{$^2$ Department of Physics, Lancaster University, Lancaster, LA1 4YB, UK }
\address{$^3$ Department of Physics and Astronomy, University of Glasgow, Glasgow G12 8QQ, UK}

\ead{jcaballero@bnl.gov}

\begin{abstract}
The ATLAS experiment at the CERN LHC is one of the largest users of grid computing
infrastructure, which is a central part of the experiment's computing operations.
Considerable efforts have been made to use grid technology in the most efficient
and effective way, including the use of a pilot job based workload management framework.
In this model the experiment submits 'pilot' jobs to sites without payload. When these
jobs begin to run they contact a central service to pick-up a real payload to execute.
The first generation of pilot factories were usually specific to a single VO, and were
bound to the particular architecture of that VO's distributed processing. A second
generation provides factories which are more flexible, not tied to any particular VO,
and provide new or improved features such as monitoring, logging, profiling, etc.
In this paper we describe this key part of the ATLAS pilot architecture, a second
generation pilot factory, AutoPyFactory.
AutoPyFactory has a modular design and is highly configurable. It is able to send
different types of pilots to sites and exploit different submission mechanisms and queue
characteristics. It is tightly integrated with the PanDA job submission framework,
coupling pilot flow to the amount of work the site has to run. It gathers information
from many sources in order to correctly configure itself for a site, and its decision logic
can easily be updated.
Integrated into AutoPyFactory is a flexible system for delivering both generic and
specific job wrappers which can perform many useful actions before starting to run
end-user scientific applications, e.g. validation of the middleware, node profiling
and diagnostics, and monitoring.
AutoPyFactory now also has a robust monitoring system and we show how this has helped
establish a reliable pilot factory service for ATLAS.
\end{abstract}


\section{Introduction}

\subsection{}

\section{Architecture}


AutoPyFactory has a modular design and is highly configurable. 
It is able to send different types of pilots to sites, 
able to exploit different submission mechanisms and different charateristics of queues at sites. 
It has excellent integration with the PanDA job submission framework, 
tying pilot flows closely to the amount of work the site has to run. 
It is able to gather information from many sources, 
in order to correctly conigure itself for a site and its decision logic can easily be updated.

\subsection{Plug-ins design}

AutoPyFactory can serve to different queues in different ways 
thanks to its modular design based on plug-ins. 
There are currently 5 types of plug-ins:

\subsubsection{WMS Status Plug-in} 
it queries a given WMS system. E.g. PandaWMSStatusPlugin queries PanDA. 
The only requirements is the WMS must provide for an API. 
This API has to return the number of jobs in different status (ready, running, finished...) per queue, 
in such a way that information can be converted internally into APF nomenclature. 

\subsubsection{Batch Status Plug-in} 
it queries the specific batch system being used to submit jobs (or pilots). 
E.g. CondorBatchStatusPlugin queries condor (condor_q)

\subsubsection{Scheduler Plugin-in} 
it is the component in charge of making a decision based on the information provided by the two Status Plug-ins. 
It implements a given algorithm to decide how many jobs (or pilots) should be submitted next cyle. 
E.g. ActivatedSchedPlugin decides the number of new jobs based on the number of jobs in a ready status in the WMS service, 
with some restrictions to prevent burning a CE. 
FixedSchedPlugin always submits a fixed number of jobs. Etc.

\subsubsection{Execution Plug-in} 
It is the component in charge of submitting new jobs (or pilots), 
based on the decision made by the Sched Plug-in. 
Examples are CondorGT2BatchSubmitPlugin, CondorGT5BatchSubmitPlugin, CondorLocalBatchSubmitPlugin, CondorCREAMBatchSubmitPlugin, and CondorEC2BatchSubmitPlugin.

\subsubsection{Configuration Plug-in} 
a plug-in to retrieve extra configuration files. 
E.g PandaConfigPlugin queries SchedConfig. 


\section{Monitor}


%%\section{Acknowledgements}
\ack{
The authors would like to thank 
}

\section*{References}
\begin{thebibliography}{99}


\item ATLAS Collaboration 1994 ATLAS Technical Proposal 
      {\it CERN/LHCC/94-43} 

\end{thebibliography}

~

%%Notice:
%%This manuscript has been authored by employees of Brookhaven Science Associates, 
%%LLC under Contract No. XXXXXXXXXX with the U.S. Department of Energy. 
%%The publisher by accepting the manuscript for publication acknowledges 
%%that the United States Government retains a non-exclusive, paid-up, irrevocable, 
%%world-wide license to publish or reproduce the published form of this manuscript, 
%%or allow others to do so, for United States Government purposes.

\end{document}

