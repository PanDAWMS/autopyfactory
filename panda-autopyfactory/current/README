autopyfactory
-------------

autopyfactory is a (still fairly) simple pilot factory for ATLAS
production. Configured sites have pilots dispatched to them depending
on their status in production (i.e., if jobs are waiting to be picked
up) and how many pilots are currently queued or running.

autopyfactory will now mainly autoconfigure itself from schedconfig
so only queue nicknames need be defined.


How the factory works:

For each site the factory looks at the status of jobs already
submitted (running and queued) and the status of the site in panda
production (particularly activated jobs, which are the jobs now ready
to run at the site).

For sites which are "online" in panda and have activated jobs
the factory ensures that a minimum depth of queued jobs are maintained
on the site. If the site has no activated jobs the factory idles the
site by sending one pilot.


How the pilot wrapper works:

The default wrapper is called runpilot3-wrapper.sh. Essentially
it changes to a proper working directory, fetches the pilot tarball
(downloaded via curl), prints out some useful debug environment 
information, finds a working python for the LFC plugin, then fires 
off the pilot code. Recently added features include sourcing the DDM 
setup code and the ATLAS local site setup scripts.


Building
--------

To build this package from source do

python setup.py bdist --formats=rpm

*** N.B. Because of a problem in the way Redhat flavour RPMs are built
you must have this rpm macro defined:

%_unpackaged_files_terminate_build 0

which prevents rpmbuild from failing because of the .pyo files which
get built automatically.

The easiest way to do this is to add that line to ~/.rpmmacros.

Monitoring
----------

With monitoring enabled autopyfactory will send HTTP_GET and HTTP_POST
requests to a remote webservice. The following requests are made:

1. HTTP_POST for each condor job CREATED  (Factory.py)
2. HTTP_GET when pilot job is RUNNING on WorkerNode (runpilot3-wrapper.sh)
3. HTTP_GET when pilot job is EXITING on WorkerNode (runpilot3-wrapper.sh)

Enable monitoring by including this line in the factory.conf, then visit 
the URL for the web interface:
monitorURL = http://py-dev.lancs.ac.uk/mon/

By default monitoring is disabled. Please email p.love@lancaster.ac.uk for
any monitoring questions.

Monitoring cron jobs
--------------------

Two cron jobs are required to run on the factory machine, these query condor 
and update the monitoring webservice about the state of each job:

1. mon-exiting.sh refreshes jobs in state EXITING.
2. mon-stale.sh notifies webservice about jobs which are stuck in particular
states based on pre-defined timeouts.

Example crontab (todo: add to rpm post-install script):
* * * * * flock -xn /tmp/LCK_mon-exiting.py -c 'python bin/mon-exiting.py -q'
* * * * * flock -xn /tmp/LCK_mon-stale.py -c 'python bin/mon-stale.py -q' 

These scripts need editing! You must change _THISFID to the name of your 
factory. eg. _THISFID = 'peter-UK-devel'
