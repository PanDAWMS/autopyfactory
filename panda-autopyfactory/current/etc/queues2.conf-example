#
# queues.conf  Configuration file for APFQueue component of AutoPyFactory.
#

## Defaults for queues - these values are set when there is not an explicit value
## If you don't set them here the factory takes sensible default values, so nothing is mandatory
## see ConfigLoader._configurationDefaults() for these values. 
#
# Most important values can now be detected from schedconfig, so there is no need to set them
# at all. These values are marked with a *. N.B. Even if you do set these values in the factory
# they will be overwritten unless the "override = True" setting is used.
#
# Some of these values may be in the process of deprecation, especially submission parameters 
# which are now handled by the submit plugins. 

# =========================================================================== 
#               VARIABLES
# =========================================================================== 

# override
#
# grid
# vo
# cloud
# batchqueue 
# wmsqueue 
# enabled
# status
# apfqueue.sleep
# autofill
#
# cleanlogs.keepdays
#
# wmsstatusplugin
#
# configplugin
#
# batchstatusplugin
#
# schedplugin
# sched.activated.default
# sched.activated.max_jobs_torun
# sched.activated.max_pilots_per_cycle
# sched.activated.min_pilots_per_cycle
# sched.activated.min_pilots_pending
# sched.activated.max_pilots_pending
# sched.activated.testmode.enabled
# sched.activated.testmode.pilots
# sched.fixed.pilotspercycle
# sched.simple.default
# sched.simple.maxpendingpilots
# sched.simple.maxpilotspercycle
# sched.simplenqueue.default
# sched.simplenqueue.maxpilotspercycle
# sched.simplenqueue.nqueue
# sched.simplenqueue.depthboost
# sched.simplenqueue.pilotlimit
# sched.simplenqueue.transferringlimit
# sched.trivial.default
#
# batchsubmitplugin
# batchsubmit.condorgt2.submitargs
# batchsubmit.condorgt2.gridresource
# batchsubmit.condorgt2.condor_attributes
# batchsubmit.condorgt2.environ
# batchsubmit.condorgt2.proxy

# globusrsl.gram2.arguments
# globusrsl.gram2.count
# globusrsl.gram2.directory
# globusrsl.gram2.dryRun
# globusrsl.gram2.environment
# globusrsl.gram2.executable
# globusrsl.gram2.gramMyJob
# globusrsl.gram2.hostCount
# globusrsl.gram2.jobType
# globusrsl.gram2.maxCpuTime
# globusrsl.gram2.maxMemory
# globusrsl.gram2.maxTime
# globusrsl.gram2.maxWallTime
# globusrsl.gram2.minMemory
# globusrsl.gram2.project
# globusrsl.gram2.queue
# globusrsl.gram2.remote_io_url
# globusrsl.gram2.restart
# globusrsl.gram2.save_state
# globusrsl.gram2.stderr
# globusrsl.gram2.stderr_position
# globusrsl.gram2.stdin
# globusrsl.gram2.stdout
# globusrsl.gram2.stdout_position
# globusrsl.gram2.two_phase
# batchsubmit.condorgt2.globusrsl
# batchsubmit.condorgt2.globusrsladd

# batchsubmit.condorgt5.submitargs
# batchsubmit.condorgt5.gridresource
# batchsubmit.condorgt5.condor_attributes
# batchsubmit.condorgt5.environ
# batchsubmit.condorgt5.proxy

# globusrsl.gram5.arguments
# globusrsl.gram5.count
# globusrsl.gram5.directory
# globusrsl.gram5.dry_run
# globusrsl.gram5.environment
# globusrsl.gram5.executable
# globusrsl.gram5.file_clean_up
# globusrsl.gram5.file_stage_in
# globusrsl.gram5.file_stage_in_shared
# globusrsl.gram5.file_stage_out
# globusrsl.gram5.gass_cache
# globusrsl.gram5.gram_my_job
# globusrsl.gram5.host_count
# globusrsl.gram5.job_type
# globusrsl.gram5.library_path
# globusrsl.gram5.loglevel
# globusrsl.gram5.logpattern
# globusrsl.gram5.max_cpu_time
# globusrsl.gram5.max_memory
# globusrsl.gram5.max_time
# globusrsl.gram5.max_wall_time
# globusrsl.gram5.min_memory
# globusrsl.gram5.project
# globusrsl.gram5.proxy_timeout
# globusrsl.gram5.queue
# globusrsl.gram5.remote_io_url
# globusrsl.gram5.restart
# globusrsl.gram5.rsl_substitution
# globusrsl.gram5.savejobdescription
# globusrsl.gram5.save_state
# globusrsl.gram5.scratch_dir
# globusrsl.gram5.stderr
# globusrsl.gram5.stderr_position
# globusrsl.gram5.stdin
# globusrsl.gram5.stdout
# globusrsl.gram5.stdout_position
# globusrsl.gram5.two_phase
# globusrsl.gram5.username
# batchsubmit.condorgt5.globusrsl
# batchsubmit.condorgt5.globusrsladd

# batchsubmit.condorcream.submitargs
# batchsubmit.condorcream.webservice
# batchsubmit.condorcream.gridresource
# batchsubmit.condorcream.condor_attributes
# batchsubmit.condorcream.environ
# batchsubmit.condorcream.queue
# batchsubmit.condorcream.port
# batchsubmit.condorcream.batch
# batchsubmit.condorcream.proxy
# batchsubmit.condorec2.submitargs
# batchsubmit.condorec2.gridresource
# batchsubmit.condorec2.condor_attributes
# batchsubmit.condorec2.environ
# batchsubmit.condorec2.ami_id
# batchsubmit.condorec2.instance_type
# batchsubmit.condorec2.user_data
# batchsubmit.condorec2.access_key_id
# batchsubmit.condorec2.secret_access_key
# batchsubmit.condorec2.proxy
# batchsubmit.condorlocal.submitargs
# batchsubmit.condorlocal.condor_attributes
# batchsubmit.condorlocal.environ
# batchsubmit.condorlocal.proxy
#
# executable
# executable.arguments

# =========================================================================== 
#               DESCRIPTION 
# =========================================================================== 

#  --------------------------------------------------------------------
#       Generic variables
#  --------------------------------------------------------------------

# override = determines if values from this config file have precedence over
#               the same values comming from different sources of information.
#               If True then schedconfig does not clobber configuration file values.
#               Valid values are True|False.
#
# cloud = is the cloud this queue is in. You should set this to suppress pilot 
#               submission when the cloud goes offline
#               N.B. Panda clouds are UPPER CASE, e.g., UK
#
# vo = Virtual Organization
#
# grid = Grid middleware flavor at the site. (e.g. OSG, EGI, NorduGrid) 
#
# batchqueue = the Batch system related queue name. 
#               E.g. the PanDA queue name (formerly called nickname)
#
# wmsqueue = the WMS system queue name. 
#               E.g. the PanDA siteid name
#
# enabled = determines if each queue section must be used by AutoPyFactory
#               or not. Allows to disable a queue without commenting out all the values. 
#               Valid values are True|False.
#
# status = can be "test", "offline" or "online"
#
# apfqueue.sleep = sleep time between cycles in APFQueue object.
#               Value is in seconds.   
#
# autofill = says if the info from this filled should be completed
#               with info from a ConfigPlugin object
#
# cleanlogs.keepdays = maximum number of days the condor logs
#               will be kept

#  --------------------------------------------------------------------
#       WMS Status Plugin variables 
#  --------------------------------------------------------------------

# wmsstatusplugin = WMS Status Plugin.

#  --------------------------------------------------------------------
#       Config Plugin variables 
#  --------------------------------------------------------------------

# configplugin = Config Plugin. 
#               Optional.
#               E.g. Panda.

#  --------------------------------------------------------------------
#       Batch Status Plugin variables 
#  --------------------------------------------------------------------

# batchstatusplugin = Batch Status Plugin.

#  --------------------------------------------------------------------
#       Sched Plugin variables 
#  --------------------------------------------------------------------

# schedplugin = specific Scheduler Plugin implementing
#               the algorithm deciding how many new pilots
#               to submit next cycle.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Activated
#  --------------------------------------------------------------------

# sched.activated.default = default number of pilots to be submitted
#               when the context information 
#               does not exist is not reliable 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_jobs_torun = maximum number of jobs running
#               simoultaneously. 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_per_cycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_per_cycle = minimum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_pending = minimum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_pending = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.testmode.enabled = Boolean variable to trigger
#               special mode of operation when the wmssite is in
#               in status = test
#
# sched.activated.testmode.pilots = number of pilots to submit
#               when the wmssite is in status = test
#               and sched.activated.testmode.enabled is True
#

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Fixed
#  --------------------------------------------------------------------

# sched.fixed.pilotspercycle = fixed number of pilots to be submitted
#               each cycle, when using the Fixed Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Simple
#  --------------------------------------------------------------------

# sched.simple.default = default number of pilots to be submitted
#               when the context information does not exist
#               or is not reliable.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpendingpilots = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpilotspercycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Simple Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is SimpleNQueue
#  --------------------------------------------------------------------

# sched.simplenqueue.default = default number of pilots to be submitted
#               when the context information does not exist 
#               or is not reliable.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.maxpilotspercycle = maximum number of pilots
#               to be submitted each cycle.
#               To be used in SimpleNQueue Scheduler Plugin.
#
# sched.simplenqueue.nqueue = desired number of pilots
#               in idle status waiting in queue to start execution.
#               To be used in SimpleNQueue Scheduler Plugin.
# sched.simplenqueue.depthboost = multiplying factor which allows more pilots 
#               to be submitted than nqueue if there are 
#               sufficient activated jobs - helps when the jobs are short 
#
# sched.simplenqueue.pilotlimit = sets a hard limit on the total number 
#               of pilots at a site, active + queued
#
# sched.simplenqueue.transferringlimit = sets a limit on the number of jobs 
#               in transferring status allowed at a site - 
#               when this limit is reached no pilots will be submitted 
#               to allow backlogs to clear

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Trivial
#  --------------------------------------------------------------------

# sched.trivial.default = default number of pilots
#               to be submitted when the context information
#               does not exist or is not reliable.
#               To be used in Trivial Scheduler Plugin.

#  --------------------------------------------------------------------
#       Batch Submit Plugin variables 
#  --------------------------------------------------------------------

# batchsubmitplugin = Batch Submit Plugin.
#               Currently available options are: CondorGT2, CondorGT5, CondorLocal, CondorEC2, CondorCREAM.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt2
#  --------------------------------------------------------------------

# batchsubmit.condorgt2.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt2.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorgt2.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorgt2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorgt2.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#

#  --------------------------------------------------------------------
#
#               The following are GRAM2 RSL variables. 
#               They are just used to build batchsubmit.condorgt2.globusrsl 
#               (if needed)
#               The globusrsl directive in the condor submission file looks like
#
#                   globusrsl=(jobtype=single)(queue=short)
#
#               Documentation can be found here:
#
#                       http://www.globus.org/toolkit/docs/2.4/gram/gram_rsl_parameters.html
#
# globusrsl.gram2.arguments
# globusrsl.gram2.count
# globusrsl.gram2.directory
# globusrsl.gram2.dryRun
# globusrsl.gram2.environment
# globusrsl.gram2.executable
# globusrsl.gram2.gramMyJob
# globusrsl.gram2.hostCount
# globusrsl.gram2.jobType
# globusrsl.gram2.maxCpuTime
# globusrsl.gram2.maxMemory
# globusrsl.gram2.maxTime
# globusrsl.gram2.maxWallTime
# globusrsl.gram2.minMemory
# globusrsl.gram2.project
# globusrsl.gram2.queue
# globusrsl.gram2.remote_io_url
# globusrsl.gram2.restart
# globusrsl.gram2.save_state
# globusrsl.gram2.stderr
# globusrsl.gram2.stderr_position
# globusrsl.gram2.stdin
# globusrsl.gram2.stdout
# globusrsl.gram2.stdout_position
# globusrsl.gram2.two_phase
#
# batchsubmit.condorgt2.globusrsl = GRAM RSL directive.
#               If this variable is not setup, then it will be built
#               programmatically from all non empty globusrsl.gram2.XYZ variables.
#               If this variable is setup, then its value
#               will be taken *verbatim*, and all possible values
#               for globusrsl.gram2.XYZ variables will be ignored. 
#
# batchsubmit.condorgt2.globusrsladd = custom fields to be added
#               *verbatim* to the GRAM RSL directive,
#               after it has been built either from 
#               batchsubmit.condorgt2.globusrsl value
#               or from all globusrsl.gram2.XYZ variables.
#               e.g. (condorsubmit=('+AccountingGroup' '\"group_atlastest.usatlas1\"')('+Requirements' 'True'))


#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt5
#  --------------------------------------------------------------------

# batchsubmit.condorgt5.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt5.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorgt5.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorgt5.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorgt5.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#
#               The following are GRAM5 RSL variables. 
#               They are just used to build batchsubmit.condorgt5.globusrsl 
#               (if needed)
#               The globusrsl directive in the condor submission file looks like
#
#                   globusrsl=(jobtype=single)(queue=short)
#
#               Documentation can be found here:
#
#                      http://www.globus.org/toolkit/docs/5.2/5.2.0/gram5/user/#gram5-user-rsl 
#
# globusrsl.gram5.arguments
# globusrsl.gram5.count
# globusrsl.gram5.directory
# globusrsl.gram5.dry_run
# globusrsl.gram5.environment
# globusrsl.gram5.executable
# globusrsl.gram5.file_clean_up
# globusrsl.gram5.file_stage_in
# globusrsl.gram5.file_stage_in_shared
# globusrsl.gram5.file_stage_out
# globusrsl.gram5.gass_cache
# globusrsl.gram5.gram_my_job
# globusrsl.gram5.host_count
# globusrsl.gram5.job_type
# globusrsl.gram5.library_path
# globusrsl.gram5.loglevel
# globusrsl.gram5.logpattern
# globusrsl.gram5.max_cpu_time
# globusrsl.gram5.max_memory
# globusrsl.gram5.max_time
# globusrsl.gram5.max_wall_time
# globusrsl.gram5.min_memory
# globusrsl.gram5.project
# globusrsl.gram5.proxy_timeout
# globusrsl.gram5.queue
# globusrsl.gram5.remote_io_url
# globusrsl.gram5.restart
# globusrsl.gram5.rsl_substitution
# globusrsl.gram5.savejobdescription
# globusrsl.gram5.save_state
# globusrsl.gram5.scratch_dir
# globusrsl.gram5.stderr
# globusrsl.gram5.stderr_position
# globusrsl.gram5.stdin
# globusrsl.gram5.stdout
# globusrsl.gram5.stdout_position
# globusrsl.gram5.two_phase
# globusrsl.gram5.username
#
# batchsubmit.condorgt5.globusrsl = GRAM RSL directive.
#               If this variable is not setup, then it will be built
#               programmatically from all non empty globusrsl.gram5.XYZ variables.
#               If this variable is setup, then its value
#               will be taken *verbatim*, and all possible values
#               for globusrsl.gram5.XYZ variables will be ignored. 
#
# batchsubmit.condorgt5.globusrsladd = custom fields to be added
#               *verbatim* to the GRAM RSL directive,
#               after it has been built either from 
#               batchsubmit.condorgt5.globusrsl value
#               or from all globusrsl.gram5.XYZ variables.
#               e.g. (condorsubmit=('+AccountingGroup' '\"group_atlastest.usatlas1\"')('+Requirements' 'True'))
#

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorcream
#  --------------------------------------------------------------------

# batchsubmit.condorcream.webservice = web service address (e.g. ce04.esc.qmul.ac.uk:8443/ce-cream/services/CREAM2)
#
# batchsubmit.condorcream.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorcream.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorcream.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorcream.queue = queue within the local batch system (e.g. short)
#
# batchsubmit.condorcream.port = port number.
#
# batchsubmit.condorcream.batch = local batch system (pbs, sge...)
#
# batchsubmit.condorcream.gridresource = grid resource, built from other vars using interpolation:
#               batchsubmit.condorcream.gridresource = %(batchsubmit.condorcream.webservice)s:%(batchsubmit.condorcream.port)s/ce-cream/services/CREAM2 %(batchsubmit.condorcream.batch)s %(batchsubmit.condorcream.queue)s
#
# batchsubmit.condorcream.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorec2
#  --------------------------------------------------------------------

# batchsubmit.condorec2.gridresource = ec2 service's URL (e.g. https://ec2.amazonaws.com/ )
#
# batchsubmit.condorec2.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorec2.condor_attributes list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#
# batchsubmit.condorec2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorec2.ami_id = identifier for the VM image, 
#               previously registered in one of Amazon's storage service (S3 or EBS)
#
# batchsubmit.condorec2.instance_type = hardware configurations for instances to run on.
#
# batchsubmit.condorec2.user_data = up to 16Kbytes of contextualization data.
#               This makes it easy for many instances to share the same VM image, but perform different work.
#
# batchsubmit.condorec2.access_key_id = path to file with the EC2 Access Key ID
#
# batchsubmit.condorec2.secret_access_key = path to file with the EC2 Secret Access Key
#
# batchsubmit.condorec2.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorlocal
#  --------------------------------------------------------------------

# batchsubmit.condorlocal.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorlocal.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       universe = vanilla
#                       transfer_executable = True
#                       should_transfer_files = YES
#                       when_to_transfer_output = ON_EXIT_OR_EVICT
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#
#               To be used in CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorlocal.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorLocal Batch Submit Plugin.
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorlocal.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#

#  --------------------------------------------------------------------
#       Executable variables 
#  --------------------------------------------------------------------

# executable = path to the script which will be run by condor. 
#              The executable can be anything, however, 
#              two possible executables are distributed with AutoPyFactory:
#
#                       - libexec/wrapper.sh 
#                       - libexec/runpilot3-wrapper.sh 
#
# executable.arguments = input options to be passed verbatim to the executable script.
#               This variable can be built making use of an auxiliar variable
#               called executable.defaultarguments
#               This proposed ancilla works as a template, and its content is
#               created on the fly from the value of other variables.
#               This mechanism is called "interpolation", docs can be found here:
#
#                   http://docs.python.org/library/configparser.html
#
#               These are two examples of this type of templates 
#               (included in the DEFAULTS block):
#
#                   executable.defaultarguments = --wrappergrid=%(grid)s \
#                               --wrapperwmsqueue=%(wmsqueue)s \
#                               --wrapperbatchqueue=%(batchqueue)s \
#                               --wrappervo=%(vo)s \
#                               --wrappertarballurl=http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz \
#                               --wrapperserverurl=http://pandaserver.cern.ch:25080/cache/pilot \
#                               --wrapperloglevel=debug
# 
#                   executable.defaultarguments =  -s %(wmsqueue)s \
#                               -h %(batchqueue)s -p 25443 \
#                               -w https://pandaserver.cern.ch  -j false  -k 0  -u user
#
# =========================================================================== 


[DEFAULT]

grid = OSG
vo = ATLAS
cloud = US
country = US
group = None
status = online
autofill = false

cleanlogs.keepdays = 7

# plugins
batchstatusplugin = Condor
wmsstatusplugin = Panda
configplugin = Panda
batchsubmitplugin = CondorGT2
schedplugin = Activated

sched.trivial.default = 0
sched.simple.default = 0
sched.simplenqueue.default = 0
sched.activated.default = 0
# defaults for testmode
sched.activated.testmode.enabled = True
sched.activated.testmode.pilots = 5

# proxy = atlas-usatlas
batchsubmit.condorgt2.proxy = None
batchsubmit.condorgt5.proxy = None
batchsubmit.condorcream.proxy = None
batchsubmit.condorec2.proxy = None
batchsubmit.condorlocal.proxy = None

# gram and globusrsl
#   jobtype and queue are given a default value.

globusrsl.gram2.arguments = ""
globusrsl.gram2.count = ""
globusrsl.gram2.directory = ""
globusrsl.gram2.dryRun = ""
globusrsl.gram2.environment = ""
globusrsl.gram2.executable = ""
globusrsl.gram2.gramMyJob = ""
globusrsl.gram2.hostCount = ""
globusrsl.gram2.jobType = single
globusrsl.gram2.maxCpuTime = ""
globusrsl.gram2.maxMemory = ""  
globusrsl.gram2.maxTime = ""
globusrsl.gram2.maxWallTime = ""
globusrsl.gram2.minMemory = "" 
globusrsl.gram2.project = ""
globusrsl.gram2.queue = short
globusrsl.gram2.remote_io_url = ""
globusrsl.gram2.restart = ""
globusrsl.gram2.save_state = ""
globusrsl.gram2.stderr = ""
globusrsl.gram2.stderr_position = ""
globusrsl.gram2.stdin = ""
globusrsl.gram2.stdout = ""
globusrsl.gram2.stdout_position = ""
globusrsl.gram2.two_phase = ""

globusrsl.gram5.arguments = ""
globusrsl.gram5.count = ""
globusrsl.gram5.directory = ""
globusrsl.gram5.dry_run = ""
globusrsl.gram5.environment = ""
globusrsl.gram5.executable = ""
globusrsl.gram5.file_clean_up = ""
globusrsl.gram5.file_stage_in = ""
globusrsl.gram5.file_stage_in_shared = ""
globusrsl.gram5.file_stage_out = ""
globusrsl.gram5.gass_cache = ""
globusrsl.gram5.gram_my_job = ""
globusrsl.gram5.host_count = ""
globusrsl.gram5.job_type = single
globusrsl.gram5.library_path = ""
globusrsl.gram5.loglevel = ""
globusrsl.gram5.logpattern = ""
globusrsl.gram5.max_cpu_time = ""
globusrsl.gram5.max_memory = ""
globusrsl.gram5.max_time = ""
globusrsl.gram5.max_wall_time = ""
globusrsl.gram5.min_memory = ""
globusrsl.gram5.project = ""
globusrsl.gram5.proxy_timeout = ""
globusrsl.gram5.queue = single
globusrsl.gram5.remote_io_url = ""
globusrsl.gram5.restart = ""
globusrsl.gram5.rsl_substitution = ""
globusrsl.gram5.savejobdescription = ""
globusrsl.gram5.save_state = ""
globusrsl.gram5.scratch_dir = ""
globusrsl.gram5.stderr = ""
globusrsl.gram5.stderr_position = ""
globusrsl.gram5.stdin = ""
globusrsl.gram5.stdout = ""
globusrsl.gram5.stdout_position = ""
globusrsl.gram5.two_phase = ""
globusrsl.gram5.username = ""


batchsubmit.condorgt2.condor_attributes = periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30),periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)

apfqueue.sleep = 360

# The following are valid for wrapper.sh
executable = /usr/libexec/wrapper.sh
executable.defaultarguments = --wrappergrid=%(grid)s --wrapperwmsqueue=%(wmsqueue)s --wrapperbatchqueue=%(batchqueue)s --wrappervo=%(vo)s --wrappertarballurl=http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz --wrapperserverurl=http://pandaserver.cern.ch:25080/cache/pilot --wrapperloglevel=debug

# The following are valid for runpilot3.sh
#executable = /usr/libexec/runpilot3.sh
#executable.defaultarguments =  -s %(wmsqueue)s -h %(batchqueue)s -p 25443 -w https://pandaserver.cern.ch  -j false  -k 0  -u user

override = True
enabled = True

# ====================================================================== 
#               Individual queue configurations
# ====================================================================== 

[ANALY_BNL_ATLAS_1]
enabled = False

wmsqueue = ANALY_BNL_ATLAS_1
batchqueue = ANALY_BNL_ATLAS_1-condor

batchsubmit.condorgt2.gridresource = gridgk05.racf.bnl.gov/jobmanager-condor
batchsubmit.condorgt2.queue = short
batchsubmit.condorgt2.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
batchsubmit.condorgt2.proxy = atlas-production

sched.activated.min_pilots_per_cycle = 0
sched.activated.max_pilots_per_cycle = 10
sched.activated.max_jobs_torun = 60

# These arguments are passed through to the payload job (e.g., the Panda pilot). 
executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache -f false -m false --user user

# If using runpilot3.sh, you only need the defaultarguments, as it seems the payload args are not necessary. 
# executable.arguments = %(executable.defaultarguments)s


