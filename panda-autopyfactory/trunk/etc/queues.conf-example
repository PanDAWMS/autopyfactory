#
# queues.conf  Configuration file for APFQueue component of AutoPyFactory.
#

## Defaults for queues - these values are set when there is not an explicit value
## If you don't set them here the factory takes sensible default values, so nothing is mandatory
## see ConfigLoader._configurationDefaults() for these values. 
#
# Some of these values may be in the process of deprecation, especially submission parameters 
# which are now handled by the submit plugins. 

# =========================================================================== 
#               VARIABLES
# =========================================================================== 

#
# grid DEPRECATED
# vo DEPRECATED
# cloud DEPRECATED
# batchqueue 
# wmsqueue 
# enabled
# status DEPRECATED
# apfqueue.sleep
#
# cleanlogs.keepdays
#
# wmsstatusplugin
# wmsstatusplugin.condor.queryargs
#
# batchstatusplugin
# batchstatus.condor.queryargs
#
# schedplugin
# sched.activated.default
# sched.activated.max_jobs_torun
# sched.activated.max_pilots_per_cycle
# sched.activated.min_pilots_per_cycle
# sched.activated.min_pilots_pending
# sched.activated.max_pilots_pending
# sched.activated.testmode.allowed
# sched.activated.testmode.pilots
# sched.ready.offset
# sched.fixed.pilotspercycle
# sched.maxpercycle.maximum
# sched.minpercycle.minimum
# sched.maxpending.maximum
# sched.minpending.minimum
# sched.maxtorun.maximum
# sched.statustest.pilots
# sched.statusoffline.pilots
# sched.simple.default
# sched.simple.maxpendingpilots
# sched.simple.maxpilotspercycle
# sched.trivial.default
# sched.scale.factor
# sched.keepnrunning.keep_running
#
# batchsubmitplugin
# batchsubmit.condorgt2.submitargs
# batchsubmit.condorgt2.gridresource
# batchsubmit.condorgt2.condor_attributes
# batchsubmit.condorgt2.environ
# batchsubmit.condorgt2.proxy
#
# globusrsl.gram2.arguments
# globusrsl.gram2.count
# globusrsl.gram2.directory
# globusrsl.gram2.dryRun
# globusrsl.gram2.environment
# globusrsl.gram2.executable
# globusrsl.gram2.gramMyJob
# globusrsl.gram2.hostCount
# globusrsl.gram2.jobType
# globusrsl.gram2.maxCpuTime
# globusrsl.gram2.maxMemory
# globusrsl.gram2.maxTime
# globusrsl.gram2.maxWallTime
# globusrsl.gram2.minMemory
# globusrsl.gram2.project
# globusrsl.gram2.queue
# globusrsl.gram2.remote_io_url
# globusrsl.gram2.restart
# globusrsl.gram2.save_state
# globusrsl.gram2.stderr
# globusrsl.gram2.stderr_position
# globusrsl.gram2.stdin
# globusrsl.gram2.stdout
# globusrsl.gram2.stdout_position
# globusrsl.gram2.two_phase
# globusrsl.gram2.globusrsl
# globusrsl.gram2.globusrsladd
#
# batchsubmit.condorgt5.submitargs
# batchsubmit.condorgt5.gridresource
# batchsubmit.condorgt5.condor_attributes
# batchsubmit.condorgt5.environ
# batchsubmit.condorgt5.proxy
#
# globusrsl.gram5.arguments
# globusrsl.gram5.count
# globusrsl.gram5.directory
# globusrsl.gram5.dry_run
# globusrsl.gram5.environment
# globusrsl.gram5.executable
# globusrsl.gram5.file_clean_up
# globusrsl.gram5.file_stage_in
# globusrsl.gram5.file_stage_in_shared
# globusrsl.gram5.file_stage_out
# globusrsl.gram5.gass_cache
# globusrsl.gram5.gram_my_job
# globusrsl.gram5.host_count
# globusrsl.gram5.job_type
# globusrsl.gram5.library_path
# globusrsl.gram5.loglevel
# globusrsl.gram5.logpattern
# globusrsl.gram5.max_cpu_time
# globusrsl.gram5.max_memory
# globusrsl.gram5.max_time
# globusrsl.gram5.max_wall_time
# globusrsl.gram5.min_memory
# globusrsl.gram5.project
# globusrsl.gram5.proxy_timeout
# globusrsl.gram5.queue
# globusrsl.gram5.remote_io_url
# globusrsl.gram5.restart
# globusrsl.gram5.rsl_substitution
# globusrsl.gram5.savejobdescription
# globusrsl.gram5.save_state
# globusrsl.gram5.scratch_dir
# globusrsl.gram5.stderr
# globusrsl.gram5.stderr_position
# globusrsl.gram5.stdin
# globusrsl.gram5.stdout
# globusrsl.gram5.stdout_position
# globusrsl.gram5.two_phase
# globusrsl.gram5.username
# globusrsl.gram5.globusrsl
# globusrsl.gram5.globusrsladd
#
# batchsubmit.condorcream.submitargs
# batchsubmit.condorcream.webservice
# batchsubmit.condorcream.gridresource
# batchsubmit.condorcream.condor_attributes
# batchsubmit.condorcream.environ
# batchsubmit.condorcream.queue
# batchsubmit.condorcream.port
# batchsubmit.condorcream.batch
# batchsubmit.condorcream.proxy
#
# batchsubmit.condorosgce.remote_condor_schedd 
# batchsubmit.condorosgce.remote_condor_collector
# batchsubmit.condorosgce.gridresource
# batchsubmit.condorosgce.proxy
# batchsubmit.condorosgce.condor_attributes
#
# batchsubmit.condorec2.submitargs
# batchsubmit.condorec2.gridresource
# batchsubmit.condorec2.condor_attributes
# batchsubmit.condorec2.environ
# batchsubmit.condorec2.ami_id
# batchsubmit.condorec2.instance_type
# batchsubmit.condorec2.user_data
# batchsubmit.condorec2.access_key_id
# batchsubmit.condorec2.secret_access_key
# batchsubmit.condorec2.proxy
#
# batchsubmit.condordeltacloud.gridresource
# batchsubmit.condordeltacloud.username
# batchsubmit.condordeltacloud.password_file
# batchsubmit.condordeltacloud.image_id
# batchsubmit.condordeltacloud.keyname
# batchsubmit.condordeltacloud.realm_id
# batchsubmit.condordeltacloud.hardware_profile
# batchsubmit.condordeltacloud.hardware_profile_memory
# batchsubmit.condordeltacloud.hardware_profile_cpu
# batchsubmit.condordeltacloud.hardware_profile_storage
# batchsubmit.condordeltacloud.user_data
#
# batchsubmit.condorlocal.submitargs
# batchsubmit.condorlocal.condor_attributes
# batchsubmit.condorlocal.environ
# batchsubmit.condorlocal.proxy
#
# batchsubmit.condorlsf.proxy
#
# batchsubmit.condornordugrid.gridresource
# nordugridrsl
# nordugridrsladd
# nordugridrsl.addenv.
#
# monitorsection
#
# executable
# executable.arguments

# =========================================================================== 
#               DESCRIPTION 
# =========================================================================== 

#  --------------------------------------------------------------------
#       Generic variables
#  --------------------------------------------------------------------

# cloud = is the cloud this queue is in. You should set this to suppress pilot 
#               submission when the cloud goes offline
#               N.B. Panda clouds are UPPER CASE, e.g., UK
#
# vo = Virtual Organization
#
# grid = Grid middleware flavor at the site. (e.g. OSG, EGI, NorduGrid) 
#
# batchqueue = the Batch system related queue name. 
#               E.g. the PanDA queue name (formerly called nickname)
#
# wmsqueue = the WMS system queue name. 
#               E.g. the PanDA siteid name
#
# enabled = determines if each queue section must be used by AutoPyFactory
#               or not. Allows to disable a queue without commenting out all the values. 
#               Valid values are True|False.
#
# status = can be "test", "offline" or "online"
#
# apfqueue.sleep = sleep time between cycles in APFQueue object.
#               Value is in seconds.   
#
# cleanlogs.keepdays = maximum number of days the condor logs
#               will be kept

#  --------------------------------------------------------------------
#       WMS Status Plugin variables 
#  --------------------------------------------------------------------

# wmsstatusplugin = WMS Status Plugin.
#
# wmsstatus.condor.queryargs = list of command line input options
#               to be included in the query command *verbatim*. E.g.
#               wmsstatus.condorqueryargs = -name <schedd_name> ... 

#  --------------------------------------------------------------------
#       Batch Status Plugin variables 
#  --------------------------------------------------------------------

# batchstatusplugin = Batch Status Plugin.
#
# batchstatus.condor.queryargs = list of command line input options
#               to be included in the query command *verbatim*. E.g. 
#               batchstatus.condor.queryargs = -name <schedd_name> -pool <centralmanagerhostname[:portnumber]>

#  --------------------------------------------------------------------
#       Sched Plugin variables 
#  --------------------------------------------------------------------

# schedplugin = specific Scheduler Plugin implementing
#               the algorithm deciding how many new pilots
#               to submit next cycle.
#               The value can be a single Plugin or a split by comma
#               list of Plugins.
#               In the case of more than one plugin, 
#               each one will acts as a filter with respect to the
#               value returned by the previous one.
#               By selecting the right combination of Plugins in a given order,
#               a complex algorithm can be built.
#               E.g., the algorithm can start by using Ready Plugin,
#               which will determine the number of pilots based on 
#               the number of activated jobs in the WMS queue and 
#               the number of already submitted pilots.
#               After that, this number can be filtered to 
#               a maximum (MaxPerCycleSchedPlugin) or a minimum (MinPerCycleSchedPlugin)
#               number of pilots.
#               Or even can be filtered to a maximum number of pilots
#               per factory (MaxPerFactorySchedPlugin)
#               Also it can be filtered depending on the status of the wmsqueue 
#               (StatusTestSchedPlugin, StatusOfflineSchedPlugin).


#  --------------------------------------------------------------------
#       Configuration when schedplugin is Activated
#  --------------------------------------------------------------------

#  IMPORTANT NOTE: Activated plugin is decommissioned. 
#                  It is not maintained anymore.

# sched.activated.default = default number of pilots to be submitted
#               when the context information 
#               does not exist is not reliable 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_jobs_torun = maximum number of jobs running
#               simoultaneously. 
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_per_cycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_per_cycle = minimum number of pilots
#               to be submitted per cycle.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.min_pilots_pending = minimum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.max_pilots_pending = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Activated Scheduler Plugin.
#
# sched.activated.testmode.allowed = Boolean variable to trigger
#               special mode of operation when the wmsqueue is in
#               in status = test
#
# sched.activated.testmode.pilots = number of pilots to submit
#               when the wmsqueue is in status = test
#               and sched.activated.testmode.allowed is True
#
# sched.activated.testmode.max_pending = maximum number of pilots 
#               permitted in pendig state when the wmsqueue is in 
#               status = test and sched.activated.testmode.allowed is True
#

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Ready 
#  --------------------------------------------------------------------

#  sched.ready.offset = the minimum value in the number of ready jobs
#               to trigger submission. 

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Fixed
#  --------------------------------------------------------------------

# sched.fixed.pilotspercycle = fixed number of pilots to be submitted
#               each cycle, when using the Fixed Scheduler Plugin.


#  --------------------------------------------------------------------
#       Configuration when schedplugin is MaxPerCycle 
#  --------------------------------------------------------------------

# sched.maxpercycle.maximum = maximum number of pilots to be submitted
#               per cycle


#  --------------------------------------------------------------------
#       Configuration when schedplugin is MinPerCycle 
#  --------------------------------------------------------------------

# sched.minpercycle.minimum = minimum number of pilots to be submitted
#               per cycle


#  --------------------------------------------------------------------
#       Configuration when schedplugin is MaxPending
#  --------------------------------------------------------------------

# sched.maxpending.maximum = maximum number of pilots to be pending
#             

#  --------------------------------------------------------------------
#       Configuration when schedplugin is MinPending 
#  --------------------------------------------------------------------

# sched.minpending.minimum = minimum number of pilots to be pending
#              

#  --------------------------------------------------------------------
#       Configuration when schedplugin is MaxToRun
#  --------------------------------------------------------------------

# sched.maxtorun.maximum = maximum number of pilots allowed to, potentially, 
#               be running at a time. 
#              

#  --------------------------------------------------------------------
#       Configuration when schedplugin is StatusTest
#  --------------------------------------------------------------------

# sched.statustest.pilots = number of pilots to submit
#               when the wmsqueue is in status = test

#  --------------------------------------------------------------------
#       Configuration when schedplugin is StatusOffline
#  --------------------------------------------------------------------

# sched.statusoffline.pilots = number of pilots to submit
#               when the wmsqueue or the cloud is in status = offline

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Simple
#  --------------------------------------------------------------------

# sched.simple.default = default number of pilots to be submitted
#               when the context information does not exist
#               or is not reliable.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpendingpilots = maximum number of pilots
#               to be idle on queue waiting to start execution.
#               To be used in Simple Scheduler Plugin.
#
# sched.simple.maxpilotspercycle = maximum number of pilots
#               to be submitted per cycle.
#               To be used in Simple Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Trivial
#  --------------------------------------------------------------------

# sched.trivial.default = default number of pilots
#               to be submitted when the context information
#               does not exist or is not reliable.
#               To be used in Trivial Scheduler Plugin.

#  --------------------------------------------------------------------
#       Configuration when schedplugin is Scale 
#  --------------------------------------------------------------------

# sched.scale.factor = scale factor to correct the previous value
#               of the number of pilots.
#               Value is a float number.


#  --------------------------------------------------------------------
#       Configuration when schedplugin is KeepNRunning
#  --------------------------------------------------------------------

# sched.keepnrunning.keep_running = number of total jobs to keep 
#               running and/or pending

#  --------------------------------------------------------------------
#       Batch Submit Plugin variables 
#  --------------------------------------------------------------------

# batchsubmitplugin = Batch Submit Plugin.
#               Currently available options are: 
#                    CondorGT2, 
#                    CondorGT5, 
#                    CondorCREAM, 
#                    CondorLocal, 
#                    CondorLSF,
#                    CondorEC2, 
#                    CondorDeltaCloud.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt2
#  --------------------------------------------------------------------

# batchsubmit.condorgt2.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt2.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorgt2.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorgt2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorgt2.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#

#  --------------------------------------------------------------------
#       GlobusRSL GRAM2 variables
#  --------------------------------------------------------------------

# gram2 =       The following are GRAM2 RSL variables. 
#               They are just used to build batchsubmit.condorgt2.globusrsl 
#               (if needed)
#               The globusrsl directive in the condor submission file looks like
#
#                   globusrsl=(jobtype=single)(queue=short)
#
#               Documentation can be found here:
#
#                       http://www.globus.org/toolkit/docs/2.4/gram/gram_rsl_parameters.html
#
# globusrsl.gram2.arguments = 
# globusrsl.gram2.count = 
# globusrsl.gram2.directory =
# globusrsl.gram2.dryRun =
# globusrsl.gram2.environment =
# globusrsl.gram2.executable =
# globusrsl.gram2.gramMyJob =
# globusrsl.gram2.hostCount =
# globusrsl.gram2.jobType =
# globusrsl.gram2.maxCpuTime =
# globusrsl.gram2.maxMemory =
# globusrsl.gram2.maxTime =
# globusrsl.gram2.maxWallTime =
# globusrsl.gram2.minMemory =
# globusrsl.gram2.project =
# globusrsl.gram2.queue =
# globusrsl.gram2.remote_io_url =
# globusrsl.gram2.restart =
# globusrsl.gram2.save_state =
# globusrsl.gram2.stderr =
# globusrsl.gram2.stderr_position =
# globusrsl.gram2.stdin =
# globusrsl.gram2.stdout =
# globusrsl.gram2.stdout_position =
# globusrsl.gram2.two_phase =
#
# globusrsl.gram2.globusrsl = GRAM RSL directive.
#               If this variable is not setup, then it will be built
#               programmatically from all non empty globusrsl.gram2.XYZ variables.
#               If this variable is setup, then its value
#               will be taken *verbatim*, and all possible values
#               for globusrsl.gram2.XYZ variables will be ignored. 
#
# globusrsl.gram2.globusrsladd = custom fields to be added
#               *verbatim* to the GRAM RSL directive,
#               after it has been built either from 
#               globusrsl.gram2.globusrsl value
#               or from all globusrsl.gram2.XYZ variables.
#               e.g. (condorsubmit=('+AccountingGroup' '\"group_atlastest.usatlas1\"')('+Requirements' 'True'))


#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorgt5
#  --------------------------------------------------------------------

# batchsubmit.condorgt5.gridresource = name of the CE (e.g. gridtest01.racf.bnl.gov/jobmanager-condor)
#
# batchsubmit.condorgt5.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorgt5.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorgt5.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorgt5.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       GlobusRSL GRAM5 variables
#  --------------------------------------------------------------------

# gram5 = The following are GRAM5 RSL variables. 
#               They are just used to build batchsubmit.condorgt5.globusrsl 
#               (if needed)
#               The globusrsl directive in the condor submission file looks like
#
#                   globusrsl=(jobtype=single)(queue=short)
#
#               Documentation can be found here:
#
#                      http://www.globus.org/toolkit/docs/5.2/5.2.0/gram5/user/#gram5-user-rsl 
#
# globusrsl.gram5.arguments =
# globusrsl.gram5.count =
# globusrsl.gram5.directory =
# globusrsl.gram5.dry_run =
# globusrsl.gram5.environment =
# globusrsl.gram5.executable =
# globusrsl.gram5.file_clean_up =
# globusrsl.gram5.file_stage_in =
# globusrsl.gram5.file_stage_in_shared =
# globusrsl.gram5.file_stage_out =
# globusrsl.gram5.gass_cache =
# globusrsl.gram5.gram_my_job =
# globusrsl.gram5.host_count =
# globusrsl.gram5.job_type =
# globusrsl.gram5.library_path =
# globusrsl.gram5.loglevel =
# globusrsl.gram5.logpattern =
# globusrsl.gram5.max_cpu_time =
# globusrsl.gram5.max_memory =
# globusrsl.gram5.max_time =
# globusrsl.gram5.max_wall_time =
# globusrsl.gram5.min_memory =
# globusrsl.gram5.project =
# globusrsl.gram5.proxy_timeout =
# globusrsl.gram5.queue =
# globusrsl.gram5.remote_io_url =
# globusrsl.gram5.restart =
# globusrsl.gram5.rsl_substitution =
# globusrsl.gram5.savejobdescription =
# globusrsl.gram5.save_state =
# globusrsl.gram5.scratch_dir =
# globusrsl.gram5.stderr =
# globusrsl.gram5.stderr_position =
# globusrsl.gram5.stdin =
# globusrsl.gram5.stdout =
# globusrsl.gram5.stdout_position =
# globusrsl.gram5.two_phase =
# globusrsl.gram5.username =
#
# globusrsl.gram5.globusrsl = GRAM RSL directive.
#               If this variable is not setup, then it will be built
#               programmatically from all non empty globusrsl.gram5.XYZ variables.
#               If this variable is setup, then its value
#               will be taken *verbatim*, and all possible values
#               for globusrsl.gram5.XYZ variables will be ignored. 
#
# globusrsl.gram5.globusrsladd = custom fields to be added
#               *verbatim* to the GRAM RSL directive,
#               after it has been built either from 
#               globusrsl.gram5.globusrsl value
#               or from all globusrsl.gram5.XYZ variables.
#               e.g. (condorsubmit=('+AccountingGroup' '\"group_atlastest.usatlas1\"')('+Requirements' 'True'))
#

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorcream
#  --------------------------------------------------------------------

# batchsubmit.condorcream.webservice = web service address (e.g. ce04.esc.qmul.ac.uk:8443/ce-cream/services/CREAM2)
#
# batchsubmit.condorcream.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorcream.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       transfer_executable = True
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       copy_to_spool = false
#
# batchsubmit.condorcream.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorcream.queue = queue within the local batch system (e.g. short)
#
# batchsubmit.condorcream.port = port number.
#
# batchsubmit.condorcream.batch = local batch system (pbs, sge...)
#
# batchsubmit.condorcream.gridresource = grid resource, built from other vars using interpolation:
#               batchsubmit.condorcream.gridresource = %(batchsubmit.condorcream.webservice)s:%(batchsubmit.condorcream.port)s/ce-cream/services/CREAM2 %(batchsubmit.condorcream.batch)s %(batchsubmit.condorcream.queue)s
#
# batchsubmit.condorcream.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorosgce
#  --------------------------------------------------------------------

# batchsubmit.condorosgce.remote_condor_schedd = condor schedd 
#
# batchsubmit.condorosgce.remote_condor_collector =  condor collector
#
# batchsubmit.condorosgce.gridresource = to be used in case schedd and collector are the same
#
# batchsubmit.condorosgce.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#
# batchsubmit.condorosgce.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*


#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorec2
#  --------------------------------------------------------------------

# batchsubmit.condorec2.gridresource = ec2 service's URL (e.g. https://ec2.amazonaws.com/ )
#
# batchsubmit.condorec2.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorec2.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#
# batchsubmit.condorec2.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorec2.ami_id = identifier for the VM image, 
#               previously registered in one of Amazon's storage service (S3 or EBS)
#
# batchsubmit.condorec2.ec2_spot_price = max price to pay, in dollars to three decimal places. e.g. .040
#
# batchsubmit.condorec2.instance_type = hardware configurations for instances to run on, .e.g m1.medium
#
# batchsubmit.condorec2.user_data = up to 16Kbytes of contextualization data.
#               This makes it easy for many instances to share the same VM image, but perform different work.
#
# batchsubmit.condorec2.access_key_id = path to file with the EC2 Access Key ID
#
# batchsubmit.condorec2.secret_access_key = path to file with the EC2 Secret Access Key
#
# batchsubmit.condorec2.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condordeltacloud
#  --------------------------------------------------------------------

# batchsubmit.condordeltacloud.gridresource = ec2 service's URL (e.g. https://deltacloud.foo.org/api )
#
# batchsubmit.condordeltacloud.username = credentials in DeltaCloud
#
# batchsubmit.condordeltacloud.password_file = path to the file with the password
#
# batchsubmit.condordeltacloud.image_id = identifier for the VM image,
#               previously registered with the cloud service.
#
# batchsubmit.condordeltacloud.keyname = in case of using SSH, 
#               the command keyname specifies the identifier of the SSH key pair to use. 
#
# batchsubmit.condordeltacloud.realm_id = selects one between multiple locations the cloud service may have.
#
# batchsubmit.condordeltacloud.hardware_profile = selects one between the multiple hardware profiles
#               the cloud service may provide
#
# batchsubmit.condordeltacloud.hardware_profile_memory = customize the hardware profile
#
# batchsubmit.condordeltacloud.hardware_profile_cpu = customize the hardware profile
#
# batchsubmit.condordeltacloud.hardware_profile_storage = customize the hardware profile
#
# batchsubmit.condordeltacloud.user_data = contextualization data

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorlocal
#  --------------------------------------------------------------------

# batchsubmit.condorlocal.submitargs = list of command line input options
#               to be included in the submission command *verbatim*
#               e.g. 
#                   batchsubmit.condorgt2.submitargs = -remote my_schedd 
#               will drive into a command like
#                   condor_submit -remote my_schedd submit.jdl
#
# batchsubmit.condorlocal.condor_attributes = list of condor attributes, 
#               splited by comma, 
#               to be included in the condor submit file *verbatim*
#               e.g. +Experiment = "ATLAS",+VO = "usatlas",+Job_Type = "cas"
#               Can be used to include any line in the Condor-G file
#               that is not otherwise added programmatically by AutoPyFactory.
#               Note the following directives are added by default:
#
#                       universe = vanilla
#                       transfer_executable = True
#                       should_transfer_files = IF_NEEDED
#                       +TransferOutput = ""
#                       stream_output=False
#                       stream_error=False
#                       notification=Error
#                       periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#
#               To be used in CondorLocal Batch Submit Plugin.
#
# batchsubmit.condorlocal.environ = list of environment variables, 
#               splitted by white spaces, 
#               to be included in the condor attribute environment *verbatim*
#               To be used by CondorLocal Batch Submit Plugin.
#               Therefore, the format should be env1=var1 env2=var2 envN=varN
#               split by whitespaces.
#
# batchsubmit.condorlocal.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.
#


#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is condorlsf
#  --------------------------------------------------------------------

# batchsubmit.condorlsf.proxy = name of the proxy handler in proxymanager for automatic proxy renewal 
#               (See etc/proxy.conf)
#               None if no automatic proxy renewal is desired.

#  --------------------------------------------------------------------
#       Configuration when batchsubmitplugin is nordugrid 
#  --------------------------------------------------------------------

# batchsubmit.condornordugrid.gridresource = name of the ARC CE
#               i.e. lcg-lrz-ce2.grid.lrz.de
#
# nordugridrsl = Entire RSL line.
#               i.e. (jobname = 'prod_pilot')(queue=lcg)(runtimeenvironment = APPS/HEP/ATLAS-SITE-LCG)(runtimeenvironment = ENV/PROXY ) (environment = ('APFFID' 'voatlas94') ('PANDA_JSID' 'voatlas94') ('GTAG' 'http://voatlas94.cern.ch/pilots/2012-11-19/LRZ-LMU_arc/$(Cluster).$(Process).out') ('RUCIO_ACCOUNT' 'pilot') ('APFCID' '$(Cluster).$(Process)') ('APFMON' 'http://apfmon.lancs.ac.uk/mon/') ('FACTORYQUEUE' 'LRZ-LMU_arc') 
#
# nordugridrsladd = A given tag to be added to the Nordugrid RSL line
#
# nordugridrsl.addenv.<XYZ> = A given tag to be added within the 'environment' tag to the Nordugrid RSL line
#               i.e. nordugridrsl.addenv.RUCIO_ACCOUNT = pilot
#                    will be added as ('RUCIO_ACCOUNT' 'pilot' )

#  --------------------------------------------------------------------
#       Monitor Section 
#  --------------------------------------------------------------------

# monitorsection = section in monitor.conf where info 
#               about the actual monitor plugin can be found.
#               The value can be a single section or a split by comma
#               list of sections.
#               Monitor plugins handle job info publishing 
#               to one or more web monitor/dashboards. 
#               To specify more than one (sections) 
#               simply use a comma-separated list.   
#

#  --------------------------------------------------------------------
#       Executable variables 
#  --------------------------------------------------------------------

# executable = path to the script which will be run by condor. 
#               The executable can be anything, however, 
#               two possible executables are distributed with AutoPyFactory:
#
#                       - libexec/wrapper.sh 
#                       - libexec/runpilot3-wrapper.sh 
#
# executable.arguments = input options to be passed verbatim to the executable script.
#               This variable can be built making use of an auxiliar variable
#               called executable.defaultarguments
#               This proposed ancilla works as a template, and its content is
#               created on the fly from the value of other variables.
#               This mechanism is called "interpolation", docs can be found here:
#
#                   http://docs.python.org/library/configparser.html
#
#               These are two examples of this type of templates 
#               (included in the DEFAULTS block):
#
#                   executable.defaultarguments = --wrappergrid=%(grid)s \
#                               --wrapperwmsqueue=%(wmsqueue)s \
#                               --wrapperbatchqueue=%(batchqueue)s \
#                               --wrappervo=%(vo)s \
#                               --wrappertarballurl=http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz \
#                               --wrapperserverurl=http://pandaserver.cern.ch:25080/cache/pilot \
#                               --wrapperloglevel=debug
# 
#                   executable.defaultarguments =  -s %(wmsqueue)s \
#                               -h %(batchqueue)s -p 25443 \
#                               -w https://pandaserver.cern.ch  -j false  -k 0  -u user
#
# =========================================================================== 


[DEFAULT]

cleanlogs.keepdays = 7

# plugins
batchstatusplugin = Condor
wmsstatusplugin = Panda
batchsubmitplugin = CondorGT2
schedplugin = Ready 
monitorsection = apfmon-lancaster



sched.trivial.default = 0
sched.simple.default = 0
sched.activated.default = 0
# defaults for testmode
sched.activated.testmode.allowed = True
sched.activated.testmode.pilots = 5

# proxy = atlas-usatlas
batchsubmit.condorgt2.proxy = None
batchsubmit.condorgt5.proxy = None
batchsubmit.condorcream.proxy = None
batchsubmit.condorec2.proxy = None
batchsubmit.condorlocal.proxy = None

# gram and globusrsl
#   jobtype and queue are given a default value.

globusrsl.gram2.arguments = ""
globusrsl.gram2.count = ""
globusrsl.gram2.directory = ""
globusrsl.gram2.dryRun = ""
globusrsl.gram2.environment = ""
globusrsl.gram2.executable = ""
globusrsl.gram2.gramMyJob = ""
globusrsl.gram2.hostCount = ""
globusrsl.gram2.jobType = single
globusrsl.gram2.maxCpuTime = ""
globusrsl.gram2.maxMemory = ""  
globusrsl.gram2.maxTime = ""
globusrsl.gram2.maxWallTime = ""
globusrsl.gram2.minMemory = "" 
globusrsl.gram2.project = ""
globusrsl.gram2.queue = short
globusrsl.gram2.remote_io_url = ""
globusrsl.gram2.restart = ""
globusrsl.gram2.save_state = ""
globusrsl.gram2.stderr = ""
globusrsl.gram2.stderr_position = ""
globusrsl.gram2.stdin = ""
globusrsl.gram2.stdout = ""
globusrsl.gram2.stdout_position = ""
globusrsl.gram2.two_phase = ""

globusrsl.gram5.arguments = ""
globusrsl.gram5.count = ""
globusrsl.gram5.directory = ""
globusrsl.gram5.dry_run = ""
globusrsl.gram5.environment = ""
globusrsl.gram5.executable = ""
globusrsl.gram5.file_clean_up = ""
globusrsl.gram5.file_stage_in = ""
globusrsl.gram5.file_stage_in_shared = ""
globusrsl.gram5.file_stage_out = ""
globusrsl.gram5.gass_cache = ""
globusrsl.gram5.gram_my_job = ""
globusrsl.gram5.host_count = ""
globusrsl.gram5.job_type = single
globusrsl.gram5.library_path = ""
globusrsl.gram5.loglevel = ""
globusrsl.gram5.logpattern = ""
globusrsl.gram5.max_cpu_time = ""
globusrsl.gram5.max_memory = ""
globusrsl.gram5.max_time = ""
globusrsl.gram5.max_wall_time = ""
globusrsl.gram5.min_memory = ""
globusrsl.gram5.project = ""
globusrsl.gram5.proxy_timeout = ""
globusrsl.gram5.queue = single
globusrsl.gram5.remote_io_url = ""
globusrsl.gram5.restart = ""
globusrsl.gram5.rsl_substitution = ""
globusrsl.gram5.savejobdescription = ""
globusrsl.gram5.save_state = ""
globusrsl.gram5.scratch_dir = ""
globusrsl.gram5.stderr = ""
globusrsl.gram5.stderr_position = ""
globusrsl.gram5.stdin = ""
globusrsl.gram5.stdout = ""
globusrsl.gram5.stdout_position = ""
globusrsl.gram5.two_phase = ""
globusrsl.gram5.username = ""


periodic_hold = periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
periodic_remove = periodic_remove=(JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400) || (JobStatus == 2 && (CurrentTime - EnteredCurrentStatus) > 604800)
batchsubmit.condorgt2.condor_attributes = %(periodic_hold)s,%(periodic_remove)s 
# GlobusResourceUnavailableTime =!= UNDEFINED means GlobusResourceUnavailableTime is not identical to UNDEFINED
# (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600)  means job in Held for longer than 1 hour
# (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400) means job Idle and globusstatus is not identical to 1 (PENDING) for longer than 1 day
# (JobStatus == 2 && (CurrentTime - EnteredCurrentStatus) > 604800)  means job running for longer than 7 days

apfqueue.sleep = 360

# The following are valid for wrapper.sh
executable = /usr/libexec/wrapper.sh
executable.defaultarguments = --wrappergrid=%(grid)s --wrapperwmsqueue=%(wmsqueue)s --wrapperbatchqueue=%(batchqueue)s --wrappervo=%(vo)s --wrappertarballurl=http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz --wrapperserverurl=http://pandaserver.cern.ch:25080/cache/pilot --wrapperloglevel=debug

# The following are valid for runpilot3.sh
#executable = /usr/libexec/runpilot3.sh
#executable.defaultarguments =  -s %(wmsqueue)s -h %(batchqueue)s -p 25443 -w https://pandaserver.cern.ch  -j false  -k 0  -u user

enabled = True


# ====================================================================== 
#               Individual queue configurations
# ====================================================================== 

# ---------------------------------------------------------------------- 
#               Local Condor example
# ---------------------------------------------------------------------- 

[ANALY_BNL_CLOUD-sl6]
enabled = False

wmsqueue = ANALY_BNL_CLOUD
batchqueue = ANALY_BNL_CLOUD

batchstatusplugin = Condor
batchsubmit = CondorLocal

batchsubmit.condorlocal.condor_attributes =  Requirements = ( Arch == "X86_64" && OpSysAndVer == "SL6" && NodeType == "atlas" ) ,request_memory = 1699 ,+AccountingGroup = "group_analy.apf"
batchsubmit.condorlocal.proxy = atlas-production

schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
sched.minpercycle.minimum = 10
sched.maxpercycle.maximum = 20
sched.maxpending.maximum = 50

# These arguments are passed through to the payload job (e.g., the Panda pilot). 
executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user



# ---------------------------------------------------------------------- 
#               GRAM example
# ---------------------------------------------------------------------- 

[ANALY_BNL_ATLAS_1]
enabled = False

wmsqueue = ANALY_BNL_ATLAS_1
batchqueue = ANALY_BNL_ATLAS_1-condor

batchsubmit.condorgt2.gridresource = gridgk05.racf.bnl.gov/jobmanager-condor
batchsubmit.condorgt2.queue = short
batchsubmit.condorgt2.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
batchsubmit.condorgt2.proxy = atlas-production

schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
sched.minpercycle.minimum = 10
sched.maxpercycle.maximum = 20
sched.maxpending.maximum = 50

# These arguments are passed through to the payload job (e.g., the Panda pilot). 
executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user

# If using runpilot3.sh, you only need the defaultarguments, as it seems the payload args are not necessary. 
# executable.arguments = %(executable.defaultarguments)s


# ---------------------------------------------------------------------- 
#               CREAM example
# ---------------------------------------------------------------------- 

[RAL-LCG2-lcgce04-grid3000M-pbs-3379]
enabled = False

batchqueue = RAL-LCG2-lcgce04-grid3000M-pbs
wmsqueue = RAL-LCG2

batchsubmitplugin = CondorCREAM

batchsubmit.condorcream.webservice = lcgce04.gridpp.rl.ac.uk
batchsubmit.condorcream.port = 8443
batchsubmit.condorcream.batch = pbs
batchsubmit.condorcream.queue = grid3000M 
batchsubmit.condorcream.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
batchsubmit.condorcream.proxy = atlas-production

schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
sched.minpercycle.minimum = 10
sched.maxpercycle.maximum = 20
sched.maxpending.maximum = 50

# These arguments are passed through to the payload job (e.g., the Panda pilot). 
executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user

# If using runpilot3.sh, you only need the defaultarguments, as it seems the payload args are not necessary. 
# executable.arguments = %(executable.defaultarguments)s


# ---------------------------------------------------------------------- 
#               Nordugrid example
# ---------------------------------------------------------------------- 

[ANALY_LRZ]
enabled = False

wmsqueue = ANALY_LRZ 
batchqueue = ANALY_LRZ

batchsubmitplugin = CondorNordugrid
batchsubmit.condornordugrid.gridresource = lcg-lrz-ce2.grid.lrz.de 
nordugridrsl.jobname = 'analy_pilot'
nordugridrsl.queue = lcg
nordugridrsl.nordugridrsladd = (runtimeenvironment = APPS/HEP/ATLAS-SITE-LCG)(runtimeenvironment = ENV/PROXY )
nordugridrsl.addenv.RUCIO_ACCOUNT = pilot

schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
sched.minpercycle.minimum = 10
sched.maxpercycle.maximum = 20
sched.maxpending.maximum = 50

executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user
