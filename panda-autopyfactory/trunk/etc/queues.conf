# =================================================================================================================
#
# queues.conf  Configuration file for APFQueue component of AutoPyFactory.
#
# Documentation: 
#   https://twiki.grid.iu.edu/bin/view/Documentation/Release3/AutoPyFactory
#   https://twiki.grid.iu.edu/bin/view/Documentation/Release3/AutoPyFactoryConfiguration#5_3_queues_conf
# 
# =================================================================================================================

[DEFAULT]

cleanlogs.keepdays = 7

# plugins
batchstatusplugin = Condor
wmsstatusplugin = Panda
batchsubmitplugin = CondorGT2
schedplugin = Ready 
monitorsection = apfmon-lancaster

sched.trivial.default = 0
sched.simple.default = 0
sched.activated.default = 0
# defaults for testmode
sched.activated.testmode.allowed = True
sched.activated.testmode.pilots = 5

# proxy = atlas-usatlas
batchsubmit.condorgt2.proxy = None
batchsubmit.condorgt5.proxy = None
batchsubmit.condorcream.proxy = None
batchsubmit.condorec2.proxy = None
batchsubmit.condorlocal.proxy = None

# gram and globusrsl
#   jobtype and queue are given a default value.

globusrsl.gram2.arguments = ""
globusrsl.gram2.count = ""
globusrsl.gram2.directory = ""
globusrsl.gram2.dryRun = ""
globusrsl.gram2.environment = ""
globusrsl.gram2.executable = ""
globusrsl.gram2.gramMyJob = ""
globusrsl.gram2.hostCount = ""
globusrsl.gram2.jobType = single
globusrsl.gram2.maxCpuTime = ""
globusrsl.gram2.maxMemory = ""  
globusrsl.gram2.maxTime = ""
globusrsl.gram2.maxWallTime = ""
globusrsl.gram2.minMemory = "" 
globusrsl.gram2.project = ""
globusrsl.gram2.queue = short
globusrsl.gram2.remote_io_url = ""
globusrsl.gram2.restart = ""
globusrsl.gram2.save_state = ""
globusrsl.gram2.stderr = ""
globusrsl.gram2.stderr_position = ""
globusrsl.gram2.stdin = ""
globusrsl.gram2.stdout = ""
globusrsl.gram2.stdout_position = ""
globusrsl.gram2.two_phase = ""

globusrsl.gram5.arguments = ""
globusrsl.gram5.count = ""
globusrsl.gram5.directory = ""
globusrsl.gram5.dry_run = ""
globusrsl.gram5.environment = ""
globusrsl.gram5.executable = ""
globusrsl.gram5.file_clean_up = ""
globusrsl.gram5.file_stage_in = ""
globusrsl.gram5.file_stage_in_shared = ""
globusrsl.gram5.file_stage_out = ""
globusrsl.gram5.gass_cache = ""
globusrsl.gram5.gram_my_job = ""
globusrsl.gram5.host_count = ""
globusrsl.gram5.job_type = single
globusrsl.gram5.library_path = ""
globusrsl.gram5.loglevel = ""
globusrsl.gram5.logpattern = ""
globusrsl.gram5.max_cpu_time = ""
globusrsl.gram5.max_memory = ""
globusrsl.gram5.max_time = ""
globusrsl.gram5.max_wall_time = ""
globusrsl.gram5.min_memory = ""
globusrsl.gram5.project = ""
globusrsl.gram5.proxy_timeout = ""
globusrsl.gram5.queue = single
globusrsl.gram5.remote_io_url = ""
globusrsl.gram5.restart = ""
globusrsl.gram5.rsl_substitution = ""
globusrsl.gram5.savejobdescription = ""
globusrsl.gram5.save_state = ""
globusrsl.gram5.scratch_dir = ""
globusrsl.gram5.stderr = ""
globusrsl.gram5.stderr_position = ""
globusrsl.gram5.stdin = ""
globusrsl.gram5.stdout = ""
globusrsl.gram5.stdout_position = ""
globusrsl.gram5.two_phase = ""
globusrsl.gram5.username = ""


periodic_hold = periodic_hold=GlobusResourceUnavailableTime =!= UNDEFINED &&(CurrentTime-GlobusResourceUnavailableTime>30)
periodic_remove = periodic_remove=(JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400) || (JobStatus == 2 && (CurrentTime - EnteredCurrentStatus) > 604800)
batchsubmit.condorgt2.condor_attributes = %(periodic_hold)s,%(periodic_remove)s 
# GlobusResourceUnavailableTime =!= UNDEFINED means GlobusResourceUnavailableTime is not identical to UNDEFINED
# (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600)  means job in Held for longer than 1 hour
# (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400) means job Idle and globusstatus is not identical to 1 (PENDING) for longer than 1 day
# (JobStatus == 2 && (CurrentTime - EnteredCurrentStatus) > 604800)  means job running for longer than 7 days

apfqueue.sleep = 360

# The following are valid for wrapper.sh
executable = /usr/libexec/wrapper.sh
grid=OSG
vo=ATLAS
executable.defaultarguments = --wrappergrid=%(grid)s --wrapperwmsqueue=%(wmsqueue)s --wrapperbatchqueue=%(batchqueue)s --wrappervo=%(vo)s --wrappertarballurl=http://dev.racf.bnl.gov/dist/wrapper/wrapper.tar.gz --wrapperserverurl=http://pandaserver.cern.ch:25080/cache/pilot --wrapperloglevel=debug

# The following are valid for runpilot3.sh
#executable = /usr/libexec/runpilot3.sh
#executable.defaultarguments =  -s %(wmsqueue)s -h %(batchqueue)s -p 25443 -w https://pandaserver.cern.ch  -j false  -k 0  -u user

enabled = True


# ====================================================================== 
#               Examples of queue configurations
# ====================================================================== 

# ---------------------------------------------------------------------- 
#               Local Condor example
# ---------------------------------------------------------------------- 

#   [ANALY_BNL_CLOUD-sl6]
#   enabled = False
#   
#   wmsqueue = ANALY_BNL_CLOUD
#   batchqueue = ANALY_BNL_CLOUD
#   
#   batchstatusplugin = Condor
#   batchsubmit = CondorLocal
#   
#   batchsubmit.condorlocal.condor_attributes =  Requirements = ( Arch == "X86_64" && OpSysAndVer == "SL6" && NodeType == "atlas" ) ,request_memory = 1699 ,+AccountingGroup = "group_analy.apf"
#   batchsubmit.condorlocal.proxy = atlas-production
#   
#   schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
#   sched.minpercycle.minimum = 10
#   sched.maxpercycle.maximum = 20
#   sched.maxpending.maximum = 50
#   
#   # These arguments are passed through to the payload job (e.g., the Panda pilot). 
#   executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user



# ---------------------------------------------------------------------- 
#               GRAM example
# ---------------------------------------------------------------------- 

#   [ANALY_BNL_ATLAS_1]
#   enabled = False
#   
#   wmsqueue = ANALY_BNL_ATLAS_1
#   batchqueue = ANALY_BNL_ATLAS_1-condor
#   
#   batchsubmit.condorgt2.gridresource = gridgk05.racf.bnl.gov/jobmanager-condor
#   batchsubmit.condorgt2.queue = short
#   batchsubmit.condorgt2.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#   batchsubmit.condorgt2.proxy = atlas-production
#   
#   schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
#   sched.minpercycle.minimum = 10
#   sched.maxpercycle.maximum = 20
#   sched.maxpending.maximum = 50
#   
#   # These arguments are passed through to the payload job (e.g., the Panda pilot). 
#   executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user
#   
#   # If using runpilot3.sh, you only need the defaultarguments, as it seems the payload args are not necessary. 
#   # executable.arguments = %(executable.defaultarguments)s


# ---------------------------------------------------------------------- 
#               CREAM example
# ---------------------------------------------------------------------- 

#   [RAL-LCG2-lcgce04-grid3000M-pbs-3379]
#   enabled = False
#   
#   batchqueue = RAL-LCG2-lcgce04-grid3000M-pbs
#   wmsqueue = RAL-LCG2
#   
#   batchsubmitplugin = CondorCREAM
#   
#   batchsubmit.condorcream.webservice = lcgce04.gridpp.rl.ac.uk
#   batchsubmit.condorcream.port = 8443
#   batchsubmit.condorcream.batch = pbs
#   batchsubmit.condorcream.queue = grid3000M 
#   batchsubmit.condorcream.condor_attributes = periodic_remove = (JobStatus == 5 && (CurrentTime - EnteredCurrentStatus) > 3600) || (JobStatus == 1 && globusstatus =!= 1 && (CurrentTime - EnteredCurrentStatus) > 86400)
#   batchsubmit.condorcream.proxy = atlas-production
#   
#   schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
#   sched.minpercycle.minimum = 10
#   sched.maxpercycle.maximum = 20
#   sched.maxpending.maximum = 50
#   
#   # These arguments are passed through to the payload job (e.g., the Panda pilot). 
#   executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user
#   
#   # If using runpilot3.sh, you only need the defaultarguments, as it seems the payload args are not necessary. 
#   # executable.arguments = %(executable.defaultarguments)s


# ---------------------------------------------------------------------- 
#               Nordugrid example
# ---------------------------------------------------------------------- 

#   [ANALY_LRZ]
#   enabled = False
#   
#   wmsqueue = ANALY_LRZ 
#   batchqueue = ANALY_LRZ
#   
#   batchsubmitplugin = CondorNordugrid
#   batchsubmit.condornordugrid.gridresource = lcg-lrz-ce2.grid.lrz.de 
#   nordugridrsl.jobname = 'analy_pilot'
#   nordugridrsl.queue = lcg
#   nordugridrsl.nordugridrsladd = (runtimeenvironment = APPS/HEP/ATLAS-SITE-LCG)(runtimeenvironment = ENV/PROXY )
#   nordugridrsl.addenv.RUCIO_ACCOUNT = pilot
#   
#   schedplugin = Ready, MinPerCycle, MaxPerCycle, MaxPending
#   sched.minpercycle.minimum = 10
#   sched.maxpercycle.maximum = 20
#   sched.maxpending.maximum = 50
#   
#   executable.arguments = %(executable.defaultarguments)s --script=pilot.py --libcode=pilotcode.tar.gz,pilotcode-rc.tar.gz --pilotsrcurl=http://panda.cern.ch:25880/cache --user user
